---
title: |
  Supplementary information for "What constrains distributional learning
  in adults"
author: Dave F. Kleinschmidt
---

```{r knitr-setup, warning=FALSE, message=FALSE, error=FALSE, echo=FALSE, results='hide'}

library(knitr)
opts_chunk$set(warning = FALSE,
               message = FALSE,
               error = FALSE,
               cache=TRUE,
               results = "hide",
               echo=opts_knit$get("rmarkdown.pandoc.to") != 'latex')

options(digits=2)

## Produce markdown-formatted figures so that pandoc knows what to do with
## the captions. requires pandoc-fignos to parse the IDs. refer to figures
## in text with {@fig:label} or just @fig:label
## 
## (see https://github.com/tomduck/pandoc-fignos)
knit_hooks$set(plot = function(x, options) {
  paste0('![', options$fig.cap, ']',
         '(', opts_knit$get('base.url'), paste(x, collapse='.'), ')',
         '{#fig:', options$label, '}')
})
## Produce markdown-formatted table captions with anchors for cross-refs.
## Requires pandoc-tablenos to parse the IDs. Refer to tables
## in text with {@tbl:label} or @tbl:label.
## Based partly on http://stackoverflow.com/a/18672268
##
## (see https://github.com/tomduck/pandoc-tablenos)
knit_hooks$set(tbl.cap = function(before, options, envir) {
  if(!before){
    paste0('\n\nTable: ', options$tbl.cap,
           ' {#tbl:', options$label, '}', sep = '')
  }
})

```

```{r preamble, cache=FALSE}

library(tidyverse)
library(dplyr)
library(glue)
library(magrittr)
library(beliefupdatr)
library(supunsup)

library(rstan)
library(brms)
library(tidybayes)
library(ggridges)

library(cowplot)
theme_set(cowplot::theme_cowplot() +
            theme(plot.title=element_text(hjust=0)))
library(latex2exp)

## devtools::install_github('kleinschmidt/daver')
library(daver)
## devtools::install_github('kleinschmidt/phonetic-sup-unsup')
library(supunsup)
## devtools::install_github('kleinschmidt/beliefupdatr')
library(beliefupdatr)

```

```{r}

## clean names from regression models

beta_name_subs <- list(
  c(":", " : "),
  c("vot_s", "VOT"),
  c("trial_s", "Trial"),
  c("bvotCond", "/b/ VOT="),
  c("supervisedunsupervised", "unsupervised")
  )

clean_beta <- function(x) str_replace_multi(x, beta_name_subs, replace_all = TRUE)

gather_betas <- function(fit) {
  beta_levels <- rownames(fixef(fit))
  fit %>%
    gather_draws(`b_.*`, regex=TRUE) %>%
    ungroup() %>%
    mutate(.variable = factor(clean_beta(str_replace(.variable, "b_", "")),
                              levels = rev(clean_beta(beta_levels))))
}

scale_beta_gt0 <- 
  scale_fill_gradient2("p(β > 0)",
                       midpoint=0.5,
                       mid=gray(0.9),
                       low=scales::muted("blue"),
                       high=scales::muted("red"))


```

# Experiment 1

The Bayesian logistic regression model for Experiment 1 was fit using `brms`
[@Burkner2017], based on the formula:

```
respP ~ 1 + bvotCond * vot_s * trial_s + (1 + vot_s | subject)
```

`respP` is 0 for a click on the /b/-initial response picture and 1 for the
/p/-initial, `bvotCond` is the experimental condition (exposure distributions),
dummy coded as 0 or 1, and `vot_s` and `trial_s` are the stimulus VOT and the
trial number, each standardized to have mean 0 and variance 1.

This formula generates fixed effects for all main effects of condition, VOT, and
trial, all two-way interactions, and the three-way interaction.

```{r expt-1-model-table, results="raw"}

b_logit_exp1 <- readRDS("models/brm_logistic_exp1.rds")
summary(b_logit_exp1)

```

```{r expt-1-model-plot, fig.width=9.4, fig.height=5.7, fig.cap="Posterior distributions for fixed-effects coefficients in Experiment 1.  Red indicates coefficients that are reliably greater than zero, and blue indicates reliably less than zero.}

b_logit_exp1 %>%
  gather_betas() %>%
  group_by(.variable) %>%
  mutate(p_gt_zero = mean(.value > 0)) %>%
  ggplot(aes(x=.value, y=.variable, fill=p_gt_zero)) +
  geom_density_ridges(relative_scale = 2) +
  scale_beta_gt0 +
  geom_vline(xintercept = 0, linetype=3) +
  labs(x = "β (log-odds of /p/ response)",
       y = "")

```


# Experiment 2

The regression model for Experiment 2 was another Bayesian logistic
mixed-effects regression model, fit with `brms` [@Burkner2017], using the
following formula:

```
respP ~ bvotCond * supervised * vot_s * trial_s + (1 + vot_s | subject)
```

This includes a main effect and all interactions with `supervised`, which codes
whether a given subject was in the supervised (0) or unsupervised (1)
condition.  All other variables were coded as in Experiment 1.

Only unlabeled trials were used to estimate the model, since responses to
labeled trials were nearly always consistent with the label and hence
uninformative about the listener's classification function at that point.

In order to calculate Bayes factors for the null hypothesis of no effect of
supervision vs. the alternative for some possibly non-zero effect via the
Savage-Dickey method [@Wagenmakers2010], I had to specify a proper prior on beta
coefficients.  By default, `brms` uses an improper (uniform) prior over the
whole real number line, which does not assign a finite, positive probability to
any value.  I chose a Student's $t$ distributions with 3 degrees of freedom,
mean 0, and scale of 1 (`student_t(3, 0, 1)` in the `brms` syntax).  This
particular prior is a good choice in this case because it has heavy tails and
therefore does not meaningfully constrain parameter estimates in the presence of
sufficient data, yet still assigns a reasonably high prior probability to 0,
which corresponds to the null hypothesis of zero effect of the corresponding
parameter.  This is important for the Savage-Dickey method because it uses the
ratio between the prior and posterior probability assigned to the parameter
value corresponding to the null hypothesis as a means of estimating the Bayes
factor (e.g., support of the evidence for or against the null hypothesis).  If
the prior is so spread out that it assigns very low probability to the null
hypothesis parameter value, then any data that leads to an estimate anywhere
near the null hypothesis parameter value will be interpreted as evidence in
favor of the null.  In this case, using a prior that assigns a relatively high
probability to the null hypothesis parameter value creates a relatively
_conservative_ test of support for the null hypothesis.

```{r}

b_logit_exp2 <- readRDS("models/b_logit_sup_v_unsup_w_prior.rds")

hyps <-
  b_logit_exp2 %>%
  fixef() %>%
  rownames() %>%
  tibble(beta = .,
         clean_beta = clean_beta(.),
         hyp = glue("{x} = 0", x=.),
         hyp_paren = glue("({x}) = 0", x=.))

hyps_test <-
  hypothesis(b_logit_exp2, hypothesis=hyps$hyp)

hyps_tbl <-
  hyps_test$hypothesis %>%
  inner_join(hyps, by=c("Hypothesis"="hyp_paren"))

```

```{r expt-2-model-plot, fig.width=15.0, fig.height=4.8, fig.cap="Posterior distributions for fixed-effects coefficients in Experiment 2.  Color shows the Bayes Factor from the Savage-Dickey test for the null hypothesis that $\beta=0$: values greater than 1 (shown in blue) indicate evidence in favor of the null (no effect), while values less than 1 (in red) indicate evidence against the null (any non-zero effect; many very small Bayes Factors have been squished to 0.01 for the purposes of visualization).  Note that VOT and trial are centered (mean 0) and scaled (variance 1).  The left panel shows the effects for all terms not involving the `unsupervised` predictor (compare with effects from Experiment 1 in Figure -@fig:expt-1-model-plot), while the right panel shows the corresponding interactions between these terms and the `unsupervised` predictor (e.g., change in effects between supervised conditions from Experiment 2 and unsupervised Experiment 1)."}

# hypothesis can generate negative values for very small BFs
bf_cleanup <- function(x) {
  ifelse(abs(x) < 1e-10, abs(x), x)
}

b_logit_exp2 %>%
  gather_betas() %>%
  group_by(.variable) %>%
  mutate(p_gt_zero = mean(.value > 0),
         unsup = ifelse(str_detect(.variable, "unsupervised"),
                        "Unsupervised-supervised differences",
                        "Main effects (supervised baseline)")) %>%
  left_join(transmute(hyps_tbl, .variable=factor(clean_beta, levels=levels(.$.variable)), BF=Evid.Ratio)) %>%
  ggplot(aes(x=.value, y=.variable, fill=bf_cleanup(BF))) +
  stat_density_ridges(from=-3, to=5, color="gray50") +
  scale_fill_gradient2("BF(β=0)", midpoint=0,
                       limits=exp(c(-2,1) * log(12.5)),
                       oob = scales::squish,
                       trans = "log10") +
  geom_vline(xintercept = 0, linetype=3) +
  labs(x = "β (log-odds of /p/ response)",
       y = "",
       title = "Regression coefficients from Experiment 2") +
  facet_wrap(.~unsup, scales="free_y")

```

