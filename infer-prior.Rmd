---
Title: What Constrains distributional learning in adults?
Author: Dave Kleinschmidt
bibliography: /home/dave/Zotero/library.bib
output:
    html_document:
        code_folding: hide
        dev: png
        keep_md: true
        md_extensions: +implicit_figures
        pandoc_args:
        - --filter
        - pandoc-crossref
    pdf_document:
        md_extensions: +implicit_figures
        keep_tex: true
        pandoc_args:
        - --filter
        - pandoc-crossref
---


```{r knitr-setup, warning=FALSE, message=FALSE, error=FALSE, echo=FALSE, results='hide'}

library(knitr)
opts_chunk$set(warning = FALSE,
               message = FALSE,
               error = FALSE,
               cache=TRUE,
               echo=opts_knit$get("rmarkdown.pandoc.to") != 'latex')

options(digits=2)

## Produce markdown-formatted figures so that pandoc knows what to do with
## the captions. requires pandoc-fignos to parse the IDs. refer to figures
## in text with {@fig:label} or just @fig:label
## 
## (see https://github.com/tomduck/pandoc-fignos)
knit_hooks$set(plot = function(x, options) {
  paste0('![', options$fig.cap, ']',
         '(', opts_knit$get('base.url'), paste(x, collapse='.'), ')',
         '{#fig:', options$label, '}')
})
## Produce markdown-formatted table captions with anchors for cross-refs.
## Requires pandoc-tablenos to parse the IDs. Refer to tables
## in text with {@tbl:label} or @tbl:label.
## Based partly on http://stackoverflow.com/a/18672268
##
## (see https://github.com/tomduck/pandoc-tablenos)
knit_hooks$set(tbl.cap = function(before, options, envir) {
  if(!before){
    paste0('\n\nTable: ', options$tbl.cap,
           ' {#tbl:', options$label, '}', sep = '')
  }
})

```

```{r preamble, cache=FALSE}

library(tidyverse)
library(beliefupdatr)
library(supunsup)

library(rstan)
library(brms)
library(tidybayes)

library(cowplot)
theme_set(cowplot::theme_cowplot() +
            theme(plot.title=element_text(hjust=0)))

## devtools::install_github('kleinschmidt/daver')
library(daver)
## devtools::install_github('kleinschmidt/phonetic-sup-unsup')
library(supunsup)
## devtools::install_github('kleinschmidt/beliefupdatr')
library(beliefupdatr)

```



# Introduction

# Experiment 1

```{r data-exp1}

data_exp1 <- supunsup::supunsup_clean %>%
  filter(supCond == 'unsupervised') %>%
  mutate(trueCat = respCategory,
         subjNum = as.numeric(factor(subject)),
         trueCatNum = as.numeric(trueCat),
         respCatNum = as.numeric(respCat))

conditions_exp1 <-
  data_exp1 %>%
  group_by(bvotCond, trueCat) %>%
  summarise(mean_vot = mean(vot)) %>%
  spread(trueCat, mean_vot) %>%
  transmute(vot_cond = paste(b, p, sep=', '),
            ideal_boundary = (b+p)/2) %>%
  ungroup() %>%
  mutate(vot_cond = factor(vot_cond, levels=vot_cond))

data_exp1 <- left_join(data_exp1, conditions_exp1, by="bvotCond")

```

```{r vot-dists-exp1, fig.width=10, fig.height=3, fig.cap="Each subject heard one of these five synthetic accents, which differ only in the distribution of VOTs of the word-initial stops. Black dashed lines show VOT distributions from a hypothetical typical talker [as estimated by @Kronrod2016]. Note that the 0 and 10ms shifted accents are reasonably close to this typical talker, while the -10, 20, and 30ms shifted accents deviate substantially."}

prior_stats_by_talker <-
  votcorpora::vot %>%
  filter(source %in% c('gva13', 'bbg09', 'buckeye'),
         place == 'lab') %>%
  mutate(source = ifelse(source %in% c('gva13', 'bbg09'),
                         'goldricketal',
                         source)) %>%
  group_by(source, prevoiced, subject, phoneme) %>%
  summarise(mu = mean(vot),
            sigma2 = var(vot),
            sigma = sd(vot),
            n = n()) %>%
  rename(category = phoneme)

prior_stats <-
  prior_stats_by_talker %>%
  filter(source == 'goldricketal', category == 'b') %>%
  group_by(source, prevoiced, category) %>%
  summarise_at(vars(mu, sigma2, sigma, n), funs(mean, var, sum)) %>%
  transmute(category,
            mean = mu_mean,
            sd = sqrt(sigma2_mean),
            n = n_sum) %>%
  bind_rows(supunsup::prior_stats %>%
              filter(source=='kronrod2012') %>%
              mutate(n = 1))

prior_lhood <- 
  prior_stats %>%
  filter(source == 'kronrod2012') %>%
  supunsup::stats_to_lhood()

prior_class <- prior_lhood %>% lhood_to_classification()


exposure_stats <- data_exp1 %>%
  group_by(vot_cond, category=trueCat) %>%
  summarise(mean=mean(vot), sd=sd(vot))

sd_noise = sqrt(82)

exposure_lhood <- exposure_stats %>%
  group_by(vot_cond) %>%
  do(supunsup::stats_to_lhood(., sd_noise))

data_exp1 %>%
  group_by(vot_cond, vot) %>%
  filter(subject == first(subject)) %>%
  tally() %>%
  ggplot(aes(x=vot)) +
  geom_bar(stat='identity', aes(y=n, fill=vot_cond)) +
  geom_line(data=prior_lhood, aes(y=lhood*1600, group=category),
            color="black", linetype=2) +
  geom_text(data=data.frame(vot_cond='-10, 30'), x = 10, y = 60,
            label = 'Typical Talker',
            color='black', hjust=0, vjust=0.3, size=3) +
  geom_text(data=data.frame(vot_cond='-10, 30'), x = 40, y = 50,
            label = 'Exposure\nTalker',
            hjust=0, vjust=0.8, size=3,
            lineheight=1) + 
  facet_grid(.~vot_cond) +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Frequency') +
  labs(title="Experiment 1: VOT distribution conditions",
       subtitle="Similarity of exposure talker to typical talker controlled by shifting means of /b/ and /p/ distributions")
  ## scale_fill_discrete('/b/, /p/\nmean VOT') ## +
  ## theme(legend.position='none')

```

## Methods

### Subjects {#sec:subjects}

```{r participants-exp1}

n_subj <- data_exp1 %>% group_by(subject) %>% summarise() %>% tally()

excluded <- supunsup::supunsup_excluded %>%
  filter(supCond == 'unsupervised') %>%
  group_by(subject, bvotCond) %>% 
  summarise() %>% 
  left_join(supunsup::excludes, by="subject") %>%
  select(subject, bvotCond, exclude80PercentAcc, rank)

n_excluded <- nrow(excluded)
n_subj_repeat <- sum(!is.na(excluded$rank))
n_subj_bad <- sum(!is.na(excluded$exclude80PercentAcc))
n_both <- n_subj_repeat + n_subj_bad - n_excluded 

n_total <- n_subj + n_excluded

n_excl_cond <- excluded %>%
  group_by(bvotCond) %>%
  tally() %>%
  arrange(n)

```

`r n_total` subjects were recruited via Amazon's Mechanical Turk. Subjects were
paid \$2.00 for participation, which took about 20 minutes. We excluded subjects
who participated more than once ($n=`r n_subj_repeat`$) or who failed to
classify VOTs reliably ($n=`r n_subj_bad`$; $n=`r n_both`$ for both reasons).
We defined reliable classification as accuracy of at least 80% at 0 and 70ms
VOT. Because some conditions had few stimuli with these VOTs, we extrapolated
subjects' responses using a logistic generalized linear model (GLM).  Excluded
subjects were roughly equally distributed across conditions (maximum of 
`r last(n_excl_cond$n)` in `r last(n_excl_cond$bvotCond)`ms /b/ VOT condition,
and minimum of `r first(n_excl_cond$n)` in `r first(n_excl_cond$bvotCond)`ms /b/
VOT condition). After these exclusions, data from `r n_subj` subjects remained
for analysis.

### Procedure

![Example trial display (beach/peach). Listeners first click on the
    green button to play the word, then click on one picture to indicate what
    they heard.](figure_manual/beach_peach.png){#fig:beach-peach}

The procedure is based on @Clayards2008. Figure -@fig:beach-peach shows an
example trial display.  On each trial, two response option images appeared,
which corresponded to one of three /b/-/p/ minimal pairs (beach/peach,
bees/peas, or beak/peak).  Subjects started each trial by clicking on a button
between the two pictures, which played the corresponding minimal pair word audio
stimulus. Subjects then clicked on the picture to indicate whether they heard
the /b/ or /p/ member of the minimal pair. Subjects performed 222 of these
trials, evenly divided between the three minimal pairs, in random order.

Each trial's word was synthesized with a voice onset time (VOT) that was
randomly drawn from a bimodal distribution, with low and high VOT clusters
implicitly corresponding to /b/ and /p/, respectively. This distribution defined
the *accent* that the subject heard, and each subject was pseudorandomly
assigned to one of five accent conditions ([@Fig:vot-dists-exp1]).

### Materials

The audio and visual stimuli we used were identical to those in
@Clayards2008. Three /b/-/p/ minimal pair audio continua were synthesized using
the 1988 Klatt synthesizer [@Klatt1980], by manipulating VOT in 10ms increments
(either adding voicing before the stop burst to create negative VOTs, or
aspiration after for positive VOTs). Within a /b/-/p/ continuum, the other
parameters were held constant, and modeled on natural tokens of the endpoints
(beach/peach, bees/peas, and beak/peak).

## Results

In order to assess distributional learning, each subject's classification
function is compared to two baselines: the category boundary for a _typical
talker_'s VOT distributions [based on @Kronrod2016], and the category boundary
based solely on the exposure talker's distributions.  I refer to the typical
talker's boundary as the "no learning" baseline, and the exposure talker's
boundary as the "complete learning" baseline.

Each subject's classification function was estimated with a Bayesian multilevel
logistic regression, using the `brms` package [@Burkner2017] for `R`
[@RCoreTeam2017].  This approach simultaneously estimates the group-level
effects of the experimental manipulation (VOT shift condition) on the /b/-/p/
category boundary location and sharpness, and each individual subjects' boundary
locations and slopes.  A multilevel approach like this has the benefit of
properly accounting for and balancing the joint uncertainty about the group- and
individual-level effects [@Gelman2007].[^shrinkage]

[^shrinkage]: One effect of using a multilevel approach is that the estimate of
    each subject's boundary is "shrunk" towards the group-level estimate.  This
    reflects the assumption that subjects are drawn from the same population,
    and hence the data from one subject in a group are informative about other
    subjects in that group (and vice versa).  The amount of this shrinkage
    depends on the amount of data available from each individual subject, and
    the consistency of the individual subject estimates.  In this case, each
    subject contributes sufficient data to make shrinkage mild, and an
    alternative analysis that estimates each subjects' boundary with a separate
    logistic GLM produces qualitatively similar effects.

```{r exp1-regression, dependson=c("data-exp1")}

data_exp1_mod <-
  data_exp1 %>%
  select(subject, bvotCond, trial, vot, respP) %>%
  mutate(vot_s = (vot - mean(vot)) / sd(vot),
         trial_s = (trial - mean(trial)) / sd(trial))

# b_logit_exp1 <- brm(respP ~ 1 + bvotCond * vot_s * trial_s + (1 + vot_s | subject),
#                     data=data_exp1_mod, family=bernoulli(), chains=4, iter=1000)
# saveRDS(b_logit_exp1, "models/brm_logistic_exp1.rds")
b_logit_exp1 <- readRDS("models/brm_logistic_exp1.rds")

# extract fitted classification functions:
# first get trials from first, second, and third thirds
exp1_blocks <-
  data_exp1_mod %>%
  group_by(block=ntile(trial, 3)) %>%
  summarise_at(vars(trial, trial_s), mean)
# overall fit (fixed effects):
data_pred <-
  cross_df(list(vot_s = seq(min(data_exp1_mod$vot_s),
                            max(data_exp1_mod$vot_s),
                            length.out=100),
                bvotCond = unique(data_exp1_mod$bvotCond),
                block = 1:3)) %>%
  left_join(exp1_blocks, by="block") %>%
  mutate(vot = vot_s * sd(data_exp1_mod$vot) + mean(data_exp1_mod$vot)) %>%
  left_join(conditions_exp1, by="bvotCond")

expt1_class <-
  fitted(b_logit_exp1, newdata=data_pred, re_formula=NA) %>%
  as_tibble() %>%
  bind_cols(data_pred)

# by-subject fit (fixed+random effects):
data_pred_subj <-
  data_exp1_mod %>%
  group_by(subject, bvotCond) %>%
  summarise() %>%
  left_join(data_pred, by="bvotCond")

expt1_class_bysub <-
  fitted(b_logit_exp1, newdata=data_pred_subj) %>%
  as_tibble() %>%
  bind_cols(data_pred_subj)

# get x-intercept (category boundary):
expt1_bounds <-
  expt1_class %>%
  group_by(bvotCond, block) %>%
  filter(abs(Estimate - 0.5) == min(abs(Estimate - 0.5)))
  
expt1_bounds_bysub <-
  expt1_class_bysub %>%
  group_by(subject, block) %>%
  filter(abs(Estimate - 0.5) == min(abs(Estimate - 0.5)))

```

```{r exp1-results, fig.width=10, fig.height=3, fig.cap="Results from experiment 1 show that distributional learning is incomplete for large shifts of VOT distributions from a typical talker's distributions"}

perfect_learning <- exposure_stats %>%
  group_by(vot_cond) %>%
  do(stats_to_lhood(.)) %>%
  lhood_to_classification()

no_learning <- prior_lhood %>%
  lhood_to_classification()

prior_bound <- no_learning %>%
  arrange(abs(prob_p - 0.5)) %>%
  filter(row_number() ==1) %>%
  pull(vot)

vot_limits <- data_exp1 %>% pull(vot) %>% range()

ggplot(expt1_class_bysub, aes(x=vot, color=vot_cond)) +
  geom_line(data=.%>%filter(block==3), aes(y=Estimate, group=subject), alpha=0.2) +
  facet_grid(.~vot_cond) +
  geom_line(data=perfect_learning, aes(y=prob_p), group=1, linetype="33", size=1,
            show.legend=FALSE) +
  geom_line(data=no_learning, aes(y=prob_p), group=1, linetype="99", color='black',
            show.legend=FALSE) +
  geom_point(data=expt1_bounds %>% filter(block==3),
             y=0.5) +
  labs(x="VOT (ms)",
       y="Probability /p/ response",
       title="Experiment 1: Classification functions",
       subtitle="Fitted with mixed effects logistic regression, predictions for final third of trials")

```

Figure [-@fig:exp1-results] shows that distributional learning is _incomplete_
for distributions that differ substantially from what a typical talker produces.
Subjects' fitted boundaries cluster around the exposure talker's boundary for
small shifts (0/40ms VOT and 10/50ms VOT), but for larger shifts subject's
boundaries fall (on average) between the typical and exposure talker.

```{r expt1-boundaries, fig.cap="Category boundaries for each subject and for each condition.  Violins show the distribution of subjects' boundaries, and the white points show the group-level boundary (with 95% Bayesian confidence intervals)"}

# estimate uncertainty of fixed effects boundaries:
exp1_bounds_fixef <-
  tidybayes::linpred_draws(b_logit_exp1, data_pred, re_formula=NA) %>%
  group_by(bvotCond, block, trial, .draw) %>%
  arrange((.value - 0.5)^2) %>%         # sort by distance from 0.5
  filter(row_number() == 1) %>%         # take the closest to 0.5
  group_by(bvotCond, block, trial) %>%
  summarise(low=quantile(vot, 0.025), high=quantile(vot, 0.975), mean=mean(vot))

expt1_bounds_bysub %>%
  group_by(subject, block) %>%
  filter(abs(Estimate - 0.5) == min(abs(Estimate - 0.5))) %>%
  filter(block==3) %>%
  ggplot(aes(x=bvotCond, y=vot, fill=bvotCond, color=bvotCond)) +
  geom_violin(alpha=0.5, color=NA) +
  ## geom_beeswarm(cex=2) +
  geom_pointrange(data = exp1_bounds_fixef %>% filter(block==3),
                  aes(y=mean, ymin=low, ymax=high),
                  color="white", show.legend=FALSE) +
  coord_flip()

```




## Discussion


# Experiment 2

# Model

# Experiment 3
